{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Researching Importing Data to Arkouda\n",
    "\n",
    "Investigation of the support for importing data to Arkouda. Sources include\n",
    "- Parquet Written from Pandas\n",
    "- HDF5 Written from Pandas\n",
    "\n",
    "## Data Types\n",
    "- HDF5\n",
    "- Parquet\n",
    "\n",
    "## Important Notes\n",
    "- Requires tables be installed, `pip install tables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _         _                   _       \n",
      "   / \\   _ __| | _____  _   _  __| | __ _ \n",
      "  / _ \\ | '__| |/ / _ \\| | | |/ _` |/ _` |\n",
      " / ___ \\| |  |   < (_) | |_| | (_| | (_| |\n",
      "/_/   \\_\\_|  |_|\\_\\___/ \\__,_|\\__,_|\\__,_|\n",
      "                                          \n",
      "\n",
      "Client Version: v2022.05.09+14.gd0b5bef2.dirty\n"
     ]
    }
   ],
   "source": [
    "import arkouda as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    }
   ],
   "source": [
    "ak.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_A</th>\n",
       "      <th>Random_B</th>\n",
       "      <th>Random_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_A  Random_B  Random_C\n",
       "0         2         2         1\n",
       "1         1         1         4\n",
       "2         3         4         3\n",
       "3         0         4         4\n",
       "4         2         3         3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = {\n",
    "    'Random_A': np.random.randint(0, 5, 5),\n",
    "    'Random_B': np.random.randint(0, 5, 5),\n",
    "    'Random_C': np.random.randint(0, 5, 5)\n",
    "}, index = np.arange(5))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to HDF5\n",
    "1) Delete the file if it already exists\n",
    "2) Write the Pandas DataFrame out to an HDF5 file. Verify file exists\n",
    "3) Verify file Exists.\n",
    "4) Verify file can be read back to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_A</th>\n",
       "      <th>Random_B</th>\n",
       "      <th>Random_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_A  Random_B  Random_C\n",
       "0         2         2         1\n",
       "1         1         1         4\n",
       "2         3         4         3\n",
       "3         0         4         4\n",
       "4         2         3         3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "out_file = '/Users/ethandebandi/Documents/save_load_testing/pandas.hdf5'\n",
    "\n",
    "# delete the file if it exists\n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "\n",
    "#write the file\n",
    "df.to_hdf(out_file, key=\"data\", format=\"table\", mode=\"w\")\n",
    "\n",
    "if os.path.isfile(out_file):\n",
    "    # load in default mode 'r'\n",
    "    rdf = pd.read_hdf(out_file, key=\"data\")\n",
    "else:\n",
    "    raise FileExistsError(f\"Unable to find HDF5 file, {out_file}\")\n",
    "\n",
    "# display the read file\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Formatting Variations\n",
    "With Pandas we can save with numerous configurations. Assuming that we will need to be able to support at least some variation, I am demonstrating some of the major differences below. All are stored with a similar root level, but there is a great deal of variance from there.\n",
    "\n",
    "### Table Format no data_columns\n",
    "This saves each row as a tuple of the form `(index, [row_data])`. This format is very tricky to read when not in Python (ie using Chapel). \n",
    "`df.to_hdf(out_file, key=\"data\", format=\"table\", mode=\"w\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Keys:\n",
      "\t['data']\n",
      "In this format data will always be under 'table':\n",
      "\t['_i_table', 'table']\n",
      "Fields stored in the hdf5 table:\n",
      "\t['index', 'values_block_0']\n",
      "Table Data stored as list of tuples.\n",
      "\t[(0, [4, 3, 4]) (1, [2, 3, 2]) (2, [3, 1, 0]) (3, [3, 1, 4])\n",
      " (4, [0, 0, 4])]\n",
      "Columns are stored in 'values_block_0_kind attribute and pickled.\n",
      "\t['Random_A', 'Random_B', 'Random_C']\n"
     ]
    }
   ],
   "source": [
    "# Format resulting from df.to_hdf(out_file, key=\"data\", format=\"table\", mode=\"w\")\n",
    "f = h5py.File('/Users/ethandebandi/Documents/save_load_testing/pandas.hdf5', 'r')\n",
    "k = list(f.keys())\n",
    "print(f\"File Keys:\\n\\t{k}\")\n",
    "\n",
    "data = f['data']\n",
    "dk = list(data.keys())\n",
    "print(f\"In this format data will always be under 'table':\\n\\t{dk}\")\n",
    "\n",
    "dset = data['table']\n",
    "fields = list(dset.dtype.fields.keys())\n",
    "print(f\"Fields stored in the hdf5 table:\\n\\t{fields}\")\n",
    "print(f\"Table Data stored as list of tuples.\\n\\t{dset[:]}\")\n",
    "\n",
    "cols_pick = dset.attrs['values_block_0_kind']\n",
    "cols = pickle.loads(cols_pick)\n",
    "print(f\"Columns are stored in 'values_block_0_kind attribute and pickled.\\n\\t{cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Format With data columns\n",
    "In this format, data is still stored as a table, but in individual fields. This format is by far the easiest to interact with.\n",
    "Please note: data_columns does not have to be Boolean, it can be a list of columns to use. THis is an oversimplification for display purposes.\n",
    "`df.to_hdf(out_file, key=\"data\", format=\"table\", mode=\"w\", data_columns=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Keys:\n",
      "\t['data']\n",
      "In this format data will always be under 'table':\n",
      "\t['_i_table', 'table']\n",
      "Each column now is formated as its own field.\n",
      "\t['index', 'Random_A', 'Random_B', 'Random_C']\n",
      "Table Data stored as list of tuples.\n",
      "\t[(0, 3, 4, 1) (1, 4, 2, 2) (2, 3, 1, 0) (3, 4, 0, 1) (4, 3, 2, 3)]\n",
      "Fields can be directly accessed with this method using dataset['field_name'].\n",
      "\tRandom_A: [3 4 3 4 3]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/Users/ethandebandi/Documents/save_load_testing/pandas_test.hdf5', 'r')\n",
    "k = list(f.keys())\n",
    "print(f\"File Keys:\\n\\t{k}\")\n",
    "\n",
    "data = f['data']\n",
    "dk = list(data.keys())\n",
    "print(f\"In this format data will always be under 'table':\\n\\t{dk}\")\n",
    "\n",
    "dset = data['table']\n",
    "fields = list(dset.dtype.fields.keys())\n",
    "print(f\"Each column now is formated as its own field.\\n\\t{fields}\")\n",
    "print(f\"Table Data stored as list of tuples.\\n\\t{dset[:]}\")\n",
    "\n",
    "ra = dset['Random_A']\n",
    "print(f\"Fields can be directly accessed with this method using dataset['field_name'].\\n\\tRandom_A: {ra}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Format with Data Columns\n",
    "Fixed formatting is not designed for querying but has faster read/write speeds. Reviewing the format, this should be the easiest  to access.\n",
    "\n",
    "`df.to_hdf(out_file, key=\"data\", format=\"fixed\", mode=\"w\", data_columns=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Keys:\n",
      "\t['data']\n",
      "In this format data will always be under 'block0_values':\n",
      "\t['axis0', 'axis1', 'block0_items', 'block0_values']\n",
      "The column names are always stored under 'block0_items':\n",
      "\t[b'Random_A', b'Random_B', b'Random_C']\n",
      "Data is stored as lists of ndarrays:\n",
      "\t[array([2, 4, 3]), array([4, 0, 3]), array([1, 3, 2]), array([0, 1, 2]), array([2, 3, 0])]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/Users/ethandebandi/Documents/save_load_testing/pandas_fixed.hdf5', 'r')\n",
    "k = list(f.keys())\n",
    "print(f\"File Keys:\\n\\t{k}\")\n",
    "\n",
    "data = f['data']\n",
    "dk = list(data.keys())\n",
    "print(f\"In this format data will always be under 'block0_values':\\n\\t{dk}\")\n",
    "\n",
    "cols = list(data['block0_items'])\n",
    "print(f\"The column names are always stored under 'block0_items':\\n\\t{cols}\")\n",
    "\n",
    "dset = list(data['block0_values'])\n",
    "print(f\"Data is stored as lists of ndarrays:\\n\\t{dset}\")\n",
    "\n",
    "print(list(data['axis1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import HDF5 into Arkouda\n",
    "Investigation of how to read into arkouda properly, ie import from Pandas\n",
    "\n",
    "## Additional Option\n",
    "We know that we can read the .hdf5 with pandas... We could read in via pandas and use our save code to create a version arkouda can read. If both can read Arkouda's version, we can remove the pandas specific one.\n",
    "\n",
    "### ISSUES\n",
    "- Confirmed what Kyle had listed in #953, columns names are encoded in an odd fashion. In order to import from pandas, we will need to find a work around for this. Pickling should not be an issue if we are running Python 3+.\n",
    "- Pickling presents the biggest issue with floats. we should be ok if we are assuming column names should not be floats.\n",
    "- Objects pickled in Python3 cannot be unpickled by Python2\n",
    "- Specify lower protocol for better compatibility.\n",
    "- PyTables uses HIGHESTPROTOCOL by default. However, can patch by\n",
    "```python\n",
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "import pandas\n",
    "\n",
    "df.to_hdf(file, key)\n",
    "```\n",
    "\n",
    "### Import Methods\n",
    "- Read with h5py, table (pytable), or pandas. Then, we can read the information out and into arkouda. Example below utilizes h5py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [4, 3, 4]) (1, [2, 3, 2]) (2, [3, 1, 0]) (3, [3, 1, 4])\n",
      " (4, [0, 0, 4])]\n",
      "[('index', '<i8'), ('values_block_0', '<i8', (3,))]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "client is not connected to a server",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb#ch0000009?line=18'>19</a>\u001b[0m df_def \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb#ch0000009?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cols)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb#ch0000009?line=20'>21</a>\u001b[0m     df_def[cols[i]] \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39;49marray(dset[:][\u001b[39m'\u001b[39;49m\u001b[39mvalues_block_0\u001b[39;49m\u001b[39m'\u001b[39;49m][:,i]\u001b[39m.\u001b[39;49mtolist())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb#ch0000009?line=22'>23</a>\u001b[0m akdf \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mDataFrame(df_def)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethandebandi/Documents/git/ArkoudaNotebooks/Import_Research.ipynb#ch0000009?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(akdf\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m())\n",
      "File \u001b[0;32m~/Documents/git/arkouda/arkouda/pdarraycreation.py:220\u001b[0m, in \u001b[0;36marray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=213'>214</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m((\u001b[39m\"\u001b[39m\u001b[39mArray exceeds allowed transfer size. Increase \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=214'>215</a>\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mak.maxTransferBytes to allow\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=215'>216</a>\u001b[0m \u001b[39m# Pack binary array data into a bytes object with a command header\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=216'>217</a>\u001b[0m \u001b[39m# including the dtype and size. If the server has a different byteorder\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=217'>218</a>\u001b[0m \u001b[39m# than our numpy array we need to swap to match since the server expects\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=218'>219</a>\u001b[0m \u001b[39m# native endian bytes\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=219'>220</a>\u001b[0m aview \u001b[39m=\u001b[39m _array_memview(a)\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=220'>221</a>\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ma\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m seg_strings=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mFalse\u001b[39;00m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=221'>222</a>\u001b[0m rep_msg \u001b[39m=\u001b[39m generic_msg(cmd\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m, args\u001b[39m=\u001b[39margs, payload\u001b[39m=\u001b[39maview, send_binary\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/git/arkouda/arkouda/pdarraycreation.py:227\u001b[0m, in \u001b[0;36m_array_memview\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=225'>226</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_memview\u001b[39m(a) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mmemoryview\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=226'>227</a>\u001b[0m     \u001b[39mif\u001b[39;00m ((get_byteorder(a\u001b[39m.\u001b[39mdtype) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m get_server_byteorder() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbig\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=227'>228</a>\u001b[0m             (get_byteorder(a\u001b[39m.\u001b[39mdtype) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m get_server_byteorder() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlittle\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=228'>229</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(a\u001b[39m.\u001b[39mbyteswap())\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/pdarraycreation.py?line=229'>230</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/git/arkouda/arkouda/dtypes.py:192\u001b[0m, in \u001b[0;36mget_server_byteorder\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=187'>188</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=188'>189</a>\u001b[0m \u001b[39mGet the server's byteorder\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=189'>190</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=190'>191</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39markouda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m--> <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=191'>192</a>\u001b[0m order \u001b[39m=\u001b[39m get_config()[\u001b[39m'\u001b[39m\u001b[39mbyteorder\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=192'>193</a>\u001b[0m \u001b[39mif\u001b[39;00m order \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mlittle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbig\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/dtypes.py?line=193'>194</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mServer byteorder must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlittle\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbig\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/git/arkouda/arkouda/client.py:578\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=557'>558</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=558'>559</a>\u001b[0m \u001b[39mGet runtime information about the server.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=559'>560</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=573'>574</a>\u001b[0m \u001b[39m    Raised if the client is not connected to a server\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=574'>575</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m serverConfig \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=577'>578</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mclient is not connected to a server\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/ethandebandi/Documents/git/arkouda/arkouda/client.py?line=579'>580</a>\u001b[0m \u001b[39mreturn\u001b[39;00m serverConfig\n",
      "\u001b[0;31mRuntimeError\u001b[0m: client is not connected to a server"
     ]
    }
   ],
   "source": [
    "# load the dataset and set attrs we need to access\n",
    "f = h5py.File('/Users/ethandebandi/Documents/save_load_testing/pandas.hdf5', 'r')\n",
    "k = list(f.keys())\n",
    "col_name_attr =  'values_block_0_kind'\n",
    "nrows_attr = 'NROWS'\n",
    "dset = f['data/table']\n",
    "\n",
    "print(dset[:])\n",
    "print(dset.dtype)\n",
    "\n",
    "# access the column names\n",
    "pickled_cols = dset.attrs[col_name_attr]\n",
    "cols = pickle.loads(pickled_cols)\n",
    "\n",
    "# Create dictionary to load to arkouda\n",
    "df_def = {}\n",
    "for i in range(len(cols)):\n",
    "    df_def[cols[i]] = ak.array(dset[:]['values_block_0'][:,i].tolist())\n",
    "    \n",
    "akdf = ak.DataFrame(df_def)\n",
    "print(akdf.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export hdf5 file to Pandas\n",
    "Arkouda HDF5 files load into pandas.\n",
    "\n",
    "**This Example does not glue together files for multi-locale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_A</th>\n",
       "      <th>Random_B</th>\n",
       "      <th>Random_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_A  Random_B  Random_C\n",
       "0         2         2         1\n",
       "1         1         1         4\n",
       "2         3         4         3\n",
       "3         0         4         4\n",
       "4         2         3         3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak_outfile = \"/Users/ethandebandi/Documents/save_load_testing/ak_test.hdf5\"\n",
    "pd_read = '/Users/ethandebandi/Documents/save_load_testing/ak_test_LOCALE0000.hdf5'\n",
    "\n",
    "# delete the file if it exists\n",
    "if os.path.isfile(pd_read):\n",
    "    os.remove(pd_read)\n",
    "\n",
    "# Write the file out using arkouda\n",
    "akdf.save_table(ak_outfile, file_format='HDF5')\n",
    "\n",
    "# Open the file with pandas\n",
    "f = h5py.File(pd_read, 'r')\n",
    "cols = list(f.keys())\n",
    "df_def = {}\n",
    "for c in cols:\n",
    "    if c == \"_arkouda_metadata\":\n",
    "        continue\n",
    "    df_def[c] = f[c][:]\n",
    "\n",
    "df = pd.DataFrame(df_def)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Parquet to Arkouda\n",
    "\n",
    "### Potential Issues\n",
    "- engine used to save from pandas are fastparquet. We want to use pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Random_A  Random_B  Random_C\n",
      "0         2         2         1\n",
      "1         1         1         4\n",
      "2         3         4         3\n",
      "3         0         4         4\n",
      "4         2         3         3 (5 rows x 3 columns)\n"
     ]
    }
   ],
   "source": [
    "out_file = '/Users/ethandebandi/Documents/save_load_testing/pandas_parquet.parquet'\n",
    "\n",
    "# delete the file if it exists\n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "\n",
    "#write the file\n",
    "df.to_parquet(out_file, engine='pyarrow')\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "t = pq.read_table(out_file)\n",
    "cols = t.column_names\n",
    "\n",
    "df_def = {}\n",
    "for c in cols:\n",
    "    df_def[c] = ak.array(t[c].to_numpy())\n",
    "    \n",
    "df = ak.DataFrame(df_def)\n",
    "print(df.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Parquet to Pandas\n",
    "I believe we can just write this directly to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_C</th>\n",
       "      <th>Random_B</th>\n",
       "      <th>Random_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_C  Random_B  Random_A\n",
       "0         1         2         2\n",
       "1         4         1         1\n",
       "2         3         4         3\n",
       "3         4         4         0\n",
       "4         3         3         2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.save_table(out_file, file_format='Parquet')\n",
    "\n",
    "pd_read = '/Users/ethandebandi/Documents/save_load_testing/pandas_parquet_LOCALE0000.parquet'\n",
    "pd.read_parquet(pd_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Notes\n",
    "- Need to be able to handle import/export pdarray, dataframe\n",
    "    - Other types?\n",
    "- parameter to tell type we are loading\n",
    "    - infer -> Multiple columns goes to DataFrame. Single goes to pdarray.\n",
    "    -pdarray\n",
    "    -dataframe\n",
    "- Should we use a parameter for `import_from` and `export_to` that will indicate any specifics that we need to handle with how different formats configure the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "disconnected from arkouda server tcp://*:5555\n"
     ]
    }
   ],
   "source": [
    "ak.disconnect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9843ec7bf92a92e5648c61892a56b72546cb6f7f783cc4fa72865bc7befe91a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('arkouda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
